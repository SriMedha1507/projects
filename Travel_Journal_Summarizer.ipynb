{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9577397-3b49-47dd-bdaf-f360c7977950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import langchain_community\n",
    "import openai\n",
    "\n",
    "print(\"All packages loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0e25bd-b044-442c-a684-07bee9b6dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f79597d1-0c5a-4b08-9e69-97b44c69ab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.26'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e186fec3-9250-4d9c-8e7a-0ad6955d8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0c9cd0-dacc-4139-853c-afbdee99be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd72380c-eb0c-4955-8583-4f343d9cbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OpenAI_API_key\"] = \"sk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ad344d-8a74-4308-b917-555347c5ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = {\"text\"},\n",
    "    template = \"\"\"Extract top three experiences, identify one lesson or travel tip and suggest a photo caption or album title:\n",
    "    Summary:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a67e42eb-6ed1-4403-83fe-343128fac7eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ChatOpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model = \"gpt-3.5-turbo\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47c5076-70b0-4135-b1a7-6acedc8161af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5e6f95-548f-4009-8799-d7eecc7161df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LLMChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summarization_chain \u001b[38;5;241m=\u001b[39m LLMChain(llm \u001b[38;5;241m=\u001b[39m llm, prompt \u001b[38;5;241m=\u001b[39m prompt_template)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LLMChain' is not defined"
     ]
    }
   ],
   "source": [
    "summarization_chain = LLMChain(llm = llm, prompt = prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e435f8f-2718-4986-90b8-0890b1810ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"\"\"Travel Journal Entry – Himachal Backpacking\n",
    "This was my first solo trip! I landed in Dharamshala and instantly\n",
    "felt at peace — the cool air, the prayer flags, the mountain dogs.\n",
    "\n",
    "Day 2 was my first real hike — Triund. I almost turned back midway but\n",
    "two fellow hikers cheered me on. Reaching the top was surreal. Hot\n",
    "Maggi + snow peaks = joy.\n",
    "Got lost in McLeod market trying to find a café someone recommended.\n",
    "Turns out I found a better one! Sat for hours with a book and momos.\n",
    "One bad experience: I didn’t carry enough cash, and my phone didn’t\n",
    "work in some remote areas.\n",
    "Last day was quiet — journaling at the Dalai Lama temple. I feel like\n",
    "I grew up a little this week.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c26d6-22f2-417d-989b-ce0e505984c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarization_chain.run({\"text\": example_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4593a-9ad1-4eba-8828-5e13ea9c935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe8936-7eb8-4f9a-a917-2a466eb1fbcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load classifier\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Define labels relevant to your goal\n",
    "labels = [\"personal experience\", \"travel tip\", \"history\", \"fact\", \"opinion\"]\n",
    "\n",
    "# Sample paragraph\n",
    "text = \"\"\"\n",
    "I visited the Taj Mahal at sunrise, and it was a breathtaking experience. The reflection of the marble on the Yamuna River was stunning.\n",
    "Later, I explored the bustling markets of Delhi. I tried street food like chaat and golgappa, which were incredibly flavorful.\n",
    "\"\"\"\n",
    "\n",
    "# Break into sentences and classify each\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# Extract sentences labeled as \"personal experience\"\n",
    "top_experiences = []\n",
    "for sent in sentences:\n",
    "    result = classifier(sent, labels)\n",
    "    if result['labels'][0] == 'personal experience' and result['scores'][0] > 0.7:\n",
    "        top_experiences.append(sent)\n",
    "\n",
    "print(\"Top Experiences:\")\n",
    "for exp in top_experiences:\n",
    "    print(\"-\", exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9084ec5-4c9c-4713-8e91-f64a4be8f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715aef2-60ea-4bfc-af27-df0889e7997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f066a7-ce54-4af4-9256-e616ab3b05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge transformers -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a366f7-ada7-497b-8611-d1edfec04669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f46f4-fb8e-4be5-b97f-d8f40e61b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de54976-a1f6-4bca-92d4-092bb193e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install all needed libraries\n",
    "!pip install -q keybert sentence-transformers transformers torch\n",
    "\n",
    "# Step 2: Import required libraries\n",
    "import torch\n",
    "from keybert import KeyBERT\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 3: Load models\n",
    "kw_model = KeyBERT()\n",
    "caption_gen = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Step 4: Input text\n",
    "text = \"\"\"\n",
    "Travel Journal Entry – Himachal Backpacking\n",
    "This was my first solo trip! I landed in Dharamshala and instantly\n",
    "felt at peace — the cool air, the prayer flags, the mountain dogs.\n",
    "\n",
    "Day 2 was my first real hike — Triund. I almost turned back midway but\n",
    "two fellow hikers cheered me on. Reaching the top was surreal. Hot\n",
    "Maggi + snow peaks = joy.\n",
    "Got lost in McLeod market trying to find a café someone recommended.\n",
    "Turns out I found a better one! Sat for hours with a book and momos.\n",
    "One bad experience: I didn’t carry enough cash, and my phone didn’t\n",
    "work in some remote areas.\n",
    "Last day was quiet — journaling at the Dalai Lama temple. I feel like\n",
    "I grew up a little this week.\n",
    "\"\"\"\n",
    "\n",
    "# Step 5: Extract top experiences using KeyBERT\n",
    "keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 3), stop_words='english', top_n=5)\n",
    "top_experiences = [kw[0] for kw in keywords]\n",
    "\n",
    "# Display extracted experiences\n",
    "print(\"Top Experiences:\")\n",
    "for exp in top_experiences:\n",
    "    print(f\"- {exp}\")\n",
    "\n",
    "# Step 6: Generate a caption\n",
    "caption_prompt = \"Write a short travel caption about: \" + \", \".join(top_experiences) + \".\"\n",
    "caption = caption_gen(caption_prompt, max_length=30, do_sample=True, temperature=0.9)[0]['generated_text']\n",
    "\n",
    "# Display caption\n",
    "print(\"\\nSuggested Caption:\\n\", caption.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f456b-a14d-4a3d-bd6d-dccd7feea812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "from keybert import KeyBERT\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load models\n",
    "kw_model = KeyBERT()\n",
    "caption_gen = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Input text\n",
    "text = \"\"\"\n",
    "Travel Journal Entry – Himachal Backpacking\n",
    "This was my first solo trip! I landed in Dharamshala and instantly\n",
    "felt at peace — the cool air, the prayer flags, the mountain dogs.\n",
    "\n",
    "Day 2 was my first real hike — Triund. I almost turned back midway but\n",
    "two fellow hikers cheered me on. Reaching the top was surreal. Hot\n",
    "Maggi + snow peaks = joy.\n",
    "Got lost in McLeod market trying to find a café someone recommended.\n",
    "Turns out I found a better one! Sat for hours with a book and momos.\n",
    "One bad experience: I didn’t carry enough cash, and my phone didn’t\n",
    "work in some remote areas.\n",
    "Last day was quiet — journaling at the Dalai Lama temple. I feel like\n",
    "I grew up a little this week.\n",
    "\"\"\"\n",
    "\n",
    "# Extract top experiences\n",
    "keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 3), stop_words='english', top_n=5)\n",
    "top_experiences = [kw[0] for kw in keywords]\n",
    "\n",
    "print(\"Top Experiences:\")\n",
    "for exp in top_experiences:\n",
    "    print(\"-\", exp)\n",
    "\n",
    "# Generate caption\n",
    "caption_prompt = \"Write a short travel caption about: \" + \", \".join(top_experiences)\n",
    "caption = caption_gen(caption_prompt, max_length=30, do_sample=True, temperature=0.9)[0]['generated_text']\n",
    "\n",
    "print(\"\\nSuggested Caption:\\n\", caption.strip())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4710e-269d-409b-8898-c5d6f04df011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)   # Confirm it's available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "281d013c-7c0d-4a1c-a213-abe8e7cde0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "KeyBERT model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption generator loaded.\n",
      "Input text loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Experiences:\n",
      "- himachal backpacking\n",
      "- entry himachal backpacking\n",
      "- himachal backpacking solo\n",
      "- journal entry himachal\n",
      "- journaling dalai\n",
      "\n",
      "Suggested Caption:\n",
      " Write a short travel caption about: himachal backpacking, entry himachal backpacking, himachal backpacking solo, journal entry himachal, journaling dalaiachal backpacking solo. Note: When the post is on the blog post page. \"In case there are other posts not here, just send me a screenshot (i.e. a picture of yourself and a name of another blogger, and I'll post that on my blog. It's not important if it's a photo of yourself and a name of another blogger.\")\n",
      "\n",
      "\n",
      "What about a photo essay?\n",
      "\n",
      "A photo essay can be a simple, simple, and free option. It can also be an essay that includes a few words of your own to give to the caption (a photo essay is not a free option or it will work no matter who is on your blog or what name they are. Posting an essay simply allows a second person to take the photo of themselves, their name, the name of another blogger, and link the first to your post if there are other ideas or stories to read and share in future blogs). After posting your essay in the same fashion as the photo essay, use the comment line and link the third person to the image to write the comment (the first person is responsible for the caption, but it is not mandatory for your posting, please do let them know if you are not the first person who takes the photo\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import\n",
    "import torch\n",
    "from keybert import KeyBERT\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# Step 2: Load models\n",
    "kw_model = KeyBERT()\n",
    "print(\"KeyBERT model loaded.\")\n",
    "\n",
    "caption_gen = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "print(\"Caption generator loaded.\")\n",
    "\n",
    "# Step 3: Input text\n",
    "text = \"\"\"\n",
    "Travel Journal Entry – Himachal Backpacking\n",
    "This was my first solo trip! I landed in Dharamshala and instantly\n",
    "felt at peace — the cool air, the prayer flags, the mountain dogs.\n",
    "\n",
    "Day 2 was my first real hike — Triund. I almost turned back midway but\n",
    "two fellow hikers cheered me on. Reaching the top was surreal. Hot\n",
    "Maggi + snow peaks = joy.\n",
    "Got lost in McLeod market trying to find a café someone recommended.\n",
    "Turns out I found a better one! Sat for hours with a book and momos.\n",
    "One bad experience: I didn’t carry enough cash, and my phone didn’t\n",
    "work in some remote areas.\n",
    "Last day was quiet — journaling at the Dalai Lama temple. I feel like\n",
    "I grew up a little this week.\n",
    "\"\"\"\n",
    "print(\"Input text loaded.\")\n",
    "\n",
    "# Step 4: Extract top experiences\n",
    "keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 3), stop_words='english', top_n=5)\n",
    "top_experiences = [kw[0] for kw in keywords]\n",
    "print(\"\\nTop Experiences:\")\n",
    "for exp in top_experiences:\n",
    "    print(\"-\", exp)\n",
    "\n",
    "# Step 5: Generate caption\n",
    "caption_prompt = \"Write a short travel caption about: \" + \", \".join(top_experiences)\n",
    "caption = caption_gen(caption_prompt, max_length=30, do_sample=True, temperature=0.9)[0]['generated_text']\n",
    "print(\"\\nSuggested Caption:\\n\", caption.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad1baa-96eb-46cf-8315-c56c456491c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
